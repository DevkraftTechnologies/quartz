---
created: 2023-08-06 16:03
aliases: 
- Research Papers
tags:
- 
cssclasses:
- 
publish:
dg-publish: false
---

<!--
tags: 
-->

<!--internal
parent:: [[]]
child:: [[]]
related:: [[]]
-->

<!--external
- [ ] []()
-->

# Research Papers

- [ ] [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
	- [ ] [Transformer â€” Attention Is All You Need Easily Explained With Illustrations](https://luv-bansal.medium.com/transformer-attention-is-all-you-need-easily-explained-with-illustrations-d38fdb06d7db#:~:text=A%20Transformer%20is%20a%20type,top%20of%20the%20transformer%20model.)
	- [ ] [Attention is all you need: understanding with example](https://medium.com/data-science-in-your-pocket/attention-is-all-you-need-understanding-with-example-c8d074c37767)
	- [ ] [Attention is all you need: Discovering the Transformer paper](https://towardsdatascience.com/attention-is-all-you-need-discovering-the-transformer-paper-73e5ff5e0634)
	- [ ] It allowed attention to work in parallel manner at a massive scale