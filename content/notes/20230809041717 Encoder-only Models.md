---
created: 2023-08-09 04:17
aliases: 
- Encoder-only Models
tags:
- rn
cssclasses:
- 
publish:
dg-publish: false
---

<!-- 
tags: 
-->

<!--internal
parent:: [[202308090324 Generating Text with Transformers]]
child:: [[]]
related:: [[]]
-->

<!--external
- [ ] []()
-->

# Encoder-only ModelsX

- [[notes/202308090432 Encoder|Encoder]]-only models (like BERT) also work as sequence-to-sequence models where the input sequence and the output sequence are of the same length
- With additional layers to the architecture, It is possible to train encoder-only models to perform classification tasks such as sentiment 

![[notes/images/Screenshot 2023-08-09 at 4.43.01 AM.png|250]]