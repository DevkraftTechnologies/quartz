{"/":{"title":"Devkraft Technologies","content":"\n# [[notes/Generative_AI.md | Generative AI]]","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":[]},"/notes/20230628030800-Checklist":{"title":"Checklist","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] []()\n--\u003e\n\n# Checklist\n\n\u003e what would be genAI first experience would be for users in an ideal scenario. \n\n- [ ] How [[notes/20230628030901 Generative AI|Generative AI]] works\n- [ ] APIs of OpenAI\n- [ ] Azure versions of [[notes/20230630042526 ChatGPT|ChatGPT]]\n- [ ] How to send customer data to such APIs.\n- [ ] How to to keep customer data private\n- [ ] [[notes/20230703043154 Vector Database|Vector Database]]/[[notes/20230703031649 Word Embedding|Embedding]]\n- [ ] How to improve accuracy and reduce hallucinations\n- [ ] How to serve structured data back to customer in consistent manner\n- [ ] (optional) Other LLMs\n- [ ] (optional) Chaining results from different LLMs\n\t- [ ] [[notes/20230703061520 LangChain|LangChain]]\n- [ ] How to experiment with and provide this to users at low cost\n","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":[""]},"/notes/20230628030801-Links":{"title":"Links","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Links\n\n\n- [ ] [Vinija Jain](https://vinija.ai/)\n  - [ ] [models](https://vinija.ai/models/)\n- [ ] [Neural Networks: Zero to Hero](https://karpathy.ai/zero-to-hero.html)\n- [ ] [Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)\n- [ ] [Awesome-LLM-Large-Language-Models-Notes ](https://github.com/kyaiooiayk/Awesome-LLM-Large-Language-Models-Notes)\n- [ ] [BLOOM Is the Most Important AI Model of the Decade](https://thealgorithmicbridge.substack.com/p/bloom-is-the-most-important-ai-model)\n- [ ] [What Is ChatGPT Doing … and Why Does It Work?](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)\n- [ ] [The Practical Guides for Large Language Models ](https://github.com/Mooler0410/LLMsPracticalGuide)\n- [ ] [Learn Large Language Models ](https://gist.github.com/rain-1/eebd5e5eb2784feecf450324e3341c8d)\n- [ ] [LLaMA - Run LLM in A Single 4GB GPU ](https://github.com/juncongmoo/pyllama)\n- [ ] [if you are curious about large language models](http://www.iasylum.net/writings/2023-03-29-if-you-are-curious-about-LLMs.html)\n- [ ] [alpaca](https://github.com/tatsu-lab/stanford_alpaca)\n  - [ ] [AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned)\n- [ ] [llama](https://github.com/facebookresearch/llama) \n- [ ] [dalai](https://github.com/cocktailpeanut/dalai)\n- [ ] [EdgeGPT](https://github.com/acheong08/EdgeGPT)\n- [ ] [GPT4all](https://github.com/nomic-ai/gpt4all)\n- [ ] [Open-Assistant](https://github.com/LAION-AI/Open-Assistant)\n- [ ] [ChatGPT](https://github.com/acheong08/ChatGPT)\n- [ ] [web-llm](https://github.com/mlc-ai/web-llm)\n- [ ] [Data Ingestion for Large Language Models](https://blog.apify.com/what-is-data-ingestion-for-large-language-models/)\n- [ ] [Generating LLM embeddings with open source models in PostgresML](https://postgresml.org/blog/generating-llm-embeddings-with-open-source-models-in-postgresml)\n- [ ] [sweep.dev](https://sweep.dev/?trk=feed-detail_main-feed-card-text)\n  - [ ] sends all code to openAI ChatGPT\n- [ ] [Vertex AI](https://cloud.google.com/vertex-ai)","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":["TODO"]},"/notes/20230628030810-Large-Language-Models-LLMs":{"title":"Large Language Models (LLMs)","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Large Language Model (LLMs)\n","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":["TODO"]},"/notes/20230628030901-Generative-AI":{"title":"Generative AI","content":"\n\u003c!--\ntags:\n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n\n- []()\n--\u003e\n\n# Generative AI\n\nGenerative AI refers to Artificial Intelligence models that generates novel data, information, or documents\n","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":[""]},"/notes/20230628030911-Build-GPT-from-scratch":{"title":"Build GPT from scratch","content":"\n\u003c!--\ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[notes/20230628031147 Generative Pretrained Transformer (GPT)|GPT]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# [Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":["TODO"]},"/notes/20230628031147-Generative-Pretrained-Transformer-GPT":{"title":"Generative Pretrained Transformer (GPT)","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[notes/20230628030901 Generative AI|Generative AI]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Generative Pretrained Transformer (GPT)\n\nGPT stands for Generative Pretrained [[notes/20230703011428 Transformers|Transformer]]\n","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":["TODO"]},"/notes/20230628031546-Generative-Adversarial-Networks-GANs":{"title":"Generative Adversarial Networks (GANs)","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Generative Adversarial Networks (GANs)\n\nGenerative Adversarial Networks or GANs are a type of neural network that uses two competing networks - a generator and a discriminator\n\n- The generator creates fake outputs, and \n- The discriminator tries to tell the difference between the fake outputs and real-world data\n\nThrough this back-and-forth process, the GAN is able to produce outputs that are indistinguishable from real data\n","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":["TODO"]},"/notes/20230628032202-How-does-GPT-work":{"title":"How does GPT work","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[notes/20230628031147 Generative Pretrained Transformer (GPT)|GPT]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] [How does GPT Obtain its Ability? Tracing Emergent Abilities of Language Models to their Sources](https://www.notion.so/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1)\n--\u003e\n\n# How does [[notes/20230628031147 Generative Pretrained Transformer (GPT)|GPT]] work\n\n","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":["TODO"]},"/notes/20230628033256-GPT-3":{"title":"GPT-3","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[notes/20230628031147 Generative Pretrained Transformer (GPT)|GPT]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] [How GPT3 Works - Visualizations and Animations](https://jalammar.github.io/how-gpt3-works-visualizations-animations/)\n--\u003e\n\n# GPT-3\n\nThe architecture is a transformer decoder model\n\n[[notes/20230628031147 Generative Pretrained Transformer (GPT)|GPT]]-3 works is novel due to it's huge scale. GPT-3 is MASSIVE. It encodes what it learns from training in 175 billion numbers (called parameters). \n\nThese numbers are used to calculate which token to generate at each run.\n\nThe untrained model starts with random parameters. Training finds values that lead to better predictions\n\nGPT-3 generates output one token at a time\n\n\n","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":["TODO"]},"/notes/20230630020251-Discriminative-AI":{"title":"Discriminative AI","content":"\n\u003c!--\ntags:\n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n\n- []()\n--\u003e\n\n# Discriminative AI\n\nDiscriminative AI is useful when we want to make some sort of **decision**\n\nFor example, we might want to predict whether someone is at risk for cancer given some biometric data - height, weight, blood pressure, etc.\n\n\u003c!-- \n![[_attachments_/Pasted image 20230630020702.png]]\n--\u003e\n\nInstead of a list of numbers as above, we might  have an image.\n\n\u003c!-- \n![[_attachments_/Pasted image 20230630020713.png]]\n--\u003e\n\nNot all Discriminative AI techniques model a [[notes/20230630021015 Conditional Distribution|Conditional Distribution]] because not all Discriminative AI methods even model a distribution in the first place.\n\nFor example, **Support Vector Machines** are **NOT** **probabilistic**, but SVM are still used for Discriminative AI\n","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":[""]},"/notes/20230630020526-Generative-AI-vs-Discriminative-AI":{"title":"Generative AI vs Discriminative AI","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Generative AI vs Discriminative AI\n\nWhen working with [[notes/20230630020251 Discriminative AI|Discriminative AI]], we don’t care about these features in and of themselves - we only care about them insofar as they help us make a decision.\n\nIn contrast, with [[notes/20230628030901 Generative AI|Generative AI]], we do care about these features themselves. \n\nIndeed, the whole goal of Generative AI is to understand how these features relate in order to generate plausible data. \n\nFor example, suppose our goal is to generate a representative sample of humans in terms of body size (considering only height and weight here for simplicity). \n\n\u003c!--\n![[notes/images/Pasted image 20230630020929.png]]\n--\u003e\n\nIn particular, it is unrealistic to have someone that tall and thin, or that short and wide; and it’s even less likely to have a sample of 3 such extremes at the same time.\n\nInstead, we need to model the statistical distribution of weight and height in the population we wish to sample from, in order to generate more realistic novel data\n\n\u003c!--\n![[notes/images/Pasted image 20230630020945.png]]\n--\u003e\n","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":[""]},"/notes/20230630020526-Generative-AI-vs-Discriminative-AI-A-mathematical-perspective":{"title":"Generative AI vs Discriminative AI - A mathematical perspective","content":"\n\u003c!--\ntags:\n--\u003e\n\n\u003c!--internal\nparent:: [[notes/20230630020526 Generative AI vs Discriminative AI]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n\n- []()\n--\u003e\n\n# Generative AI vs Discriminative AI - A Mathematical Perspective\n\nDiscriminative AI is considered to be modeling a **[[notes/20230630021015 Conditional Distribution|Conditional Distribution]]** whereas Generative AI is considered to be modeling a **[[notes/20230630021029 Joint Distribution|Joint Distribution]]**\n\n![[notes/images/Pasted image 20230630035154.png]]\n","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":["rn"]},"/notes/20230630021015-Conditional-Distribution":{"title":"Conditional Distribution","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Conditional Distribution\n\nA conditional distribution provides the probability of A occurring given B\n\nFor example, we can ask what the probability of rolling a specific number on a 6 sided die is. \n\nFor a fair die, the probability will be ⅙ for all numbers on the die. \n\nNow, consider how these probabilities change when we are given extra information. What if we are told that the number we rolled was even? \n\nWith this information, the probabilities the number being a 1, 3, or 5 are now zero, and the probabilities of rolling a 2, 4, or 6 are now ⅓.\n","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":[""]},"/notes/20230630021029-Joint-Distribution":{"title":"Joint Distribution","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Joint Distribution\n\nA joint distribution provides the probability of A occurring alongside B\n\nFor example, what is the probability of rolling a 2 on a first die roll and a 3 on a second die roll? \n\nIn this case, probability is 1/36 assuming, again, that the die is fair.\n","lastmodified":"2023-07-24T06:16:07.102957233Z","tags":[""]},"/notes/20230630041814-Generative-AI-A-Mathematical-Perspective":{"title":"Generative AI - A Mathematical Perspective","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[notes/20230628030901 Generative AI|Generative AI]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n#  Generative AI - A Mathematical Perspective\n\nGenerative AI is modeling a [[notes/20230630021029 Joint Distribution|Joint Distribution]] because the distribution itself is the object of interest\n\nonce we model the distribution, we can use it for different outcomes\n\n- we can perform density estimates for example estimating the probabilities of someone being taller than 71 in (180 cm) and lighter than 150 lbs (68 kg)\n- we can sample from this distribution to generate novel data, which we can do for various reasons.\n  - use the generated data to train another AI model.\n  - use the generated data in its own right as we do with models like DALL-E 2","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["rn"]},"/notes/20230630042526-ChatGPT":{"title":"ChatGPT","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[notes/20230628031147 Generative Pretrained Transformer (GPT)|GPT]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] [How ChatGPT actually works](https://www.assemblyai.com/blog/how-chatgpt-actually-works/)\n--\u003e\n\n# ChatGPT\n\nChatGPT uses [[notes/20230628031546 Generative Adversarial Networks (GANs)|GANs]] to generate responses to input text, allowing it to engage in natural-sounding conversations with humans","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/20230630042902-How-to-use-Generative-AI":{"title":"How to use Generative AI","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# How to use Generative AI\n\nThe most general way to think about [[notes/20230628030901 Generative AI|Generative AI]] is as a mapping from (potential) antecedents to desired consequents\n\nLet’s say that the **goal** is to become the preeminent brand in the X market. \n\nA Y% increase in shares of  roduct X on social media is the **measurable outcome** that serves as a good **proxy** for **measuring progress** towards our **goal**.\n\n![[notes/images/Pasted image 20230630043715.png]]\n\nwhat we are doing is seeking to **implement some change or idea** (an antecedent) that will lead to the **desired outcome** (the consequent).\n\n![[notes/images/Pasted image 20230630043923.png]]\n\nwe don’t _know_ if an idea is  an antecedent. That is, will the implementation of this idea actually lead to the desired consequent? \n\nTherefore it is our job to investigate, implement, and iterate on multiple potential antecedents in an attempt to observe the desired consequent\n\nWe must establish, to the best of our ability, that an idea is in fact an antecedent to the desired consequent - i.e. that the change **entails** the consequent\n\n![[notes/images/Pasted image 20230702204208.png]]\n\n\nThe critical point here is that **the implementation details of the potential antecedents are the bottleneck in this process**. \n\nIt is straightforward to think of what outcome we _want_ and to think of what change _might lead_ to that result\n\nbut the details of _how_ we bridge the two is the challenge. \n\nRegardless of the specific domain, the **human implementation details** are where the bulk of the work is to be done and where the bottleneck occurs.\n\n![[notes/images/Pasted image 20230702204251.png]]\n\nGenerative AI can be thought of **as a tool to build the bridge between the potential antecedents and the desired consequent**.\n\n![[notes/images/Pasted image 20230702204452.png]]\n\nwe can use Generative AI in order to **expedite implementation details** involved with putting these ideas into action\n\nfor ex. use Generative AI to [[notes/20230702210325 Add a button to product page to share the product|add a button to product page to share the product]]","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["TODO"]},"/notes/20230702204625-Modern-Generative-AI":{"title":"Modern Generative AI","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Modern Generative AI\n\n[[notes/20230628030901 Generative AI|Generative AI]] is not a new tech, but the recent explosion in performance and interest can be attributed to advances made in the last 5 years\n\nIn the image space (models like [DALL-E 2](https://www.assemblyai.com/blog/how-dall-e-2-actually-works/), [Imagen](https://www.assemblyai.com/blog/how-imagen-actually-works/), [Stable Diffusion](https://www.assemblyai.com/blog/stable-diffusion-1-vs-2-what-you-need-to-know/), etc.), advances have relied on the development of [Diffusion Models](https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/).\n\nIn the language space (models like [ChatGPT](https://www.assemblyai.com/blog/how-chatgpt-actually-works/), GPT-4, etc.), advances have been made by the [scaling](https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models/) of the [Transformer](https://www.youtube.com/watch?v=_UVfwBqcnbM\u0026ref=assemblyai.com) architecture.","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["rn"]},"/notes/20230702210325-Add-a-button-to-product-page-to-share-the-product":{"title":"Add a button to product page to share the product","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Add a button to product page to share the product\n\nFrom a technical standpoint, implementing this change (i.e. adding this button) can take a bit of time\n\n- we might have to design a component that matches the website\n- we might have to incorporate it into a template so it shows up on multiple pages \n- we have to explore how the APIs of external social media platforms work\n- we might have to require login first or account creation, which would require interacting with a database\n\nwe can use Generative AI to write the (straightforward) code to make this happen \n\nAsk ChatGPT to write a simple Next.js component that implements these social share buttons\n\n```\nwrite a Next.js component that contains buttons to share the current page on social media\n```\n\n![[notes/images/Pasted image 20230702212152.png]]\n\nThe main human work that would need to be done is review. \n\nNote that the model even gives an explanation of the code which would make the review time even quicker\n\nwe can go further and ask the model to add style to our component using some specific tools in our stack\n\n![[notes/images/Pasted image 20230702212238.png]]\n\n```js\nimport { useRouter } from 'next/router';\nimport { makeStyles } from '@material-ui/core/styles';\nimport Button from '@material-ui/core/Button';\n\nconst useStyles = makeStyles((theme) =\u003e ({\n  button: {\n    margin: theme.spacing(1),\n    boxShadow: 'none',\n    '\u0026:hover': {\n      boxShadow: theme.shadows[4],\n    },\n  },\n}));\n\nconst ShareButtons = () =\u003e {\n  const router = useRouter();\n  const pageUrl = `https://yourwebsite.com${router.asPath}`;\n  const classes = useStyles();\n\n  const shareOnTwitter = () =\u003e {\n    window.open(`https://twitter.com/intent/tweet?url=${pageUrl}`);\n  };\n\n  const shareOnFacebook = () =\u003e {\n    window.open(`https://www.facebook.com/sharer/sharer.php?u=${pageUrl}`);\n  };\n\n  const shareOnLinkedIn = () =\u003e {\n    window.open(`https://www.linkedin.com/sharing/share-offsite/?url=${pageUrl}`);\n  };\n\n  return (\n    \u003cdiv\u003e\n      \u003cButton variant=\"contained\" color=\"primary\" className={classes.button} onClick={shareOnTwitter}\u003e\n        Share on Twitter\n      \u003c/Button\u003e\n      \u003cButton variant=\"contained\" color=\"primary\" className={classes.button} onClick={shareOnFacebook}\u003e\n        Share on Facebook\n      \u003c/Button\u003e\n      \u003cButton variant=\"contained\" color=\"primary\" className={classes.button} onClick={shareOnLinkedIn}\u003e\n        Share on LinkedIn\n      \u003c/Button\u003e\n    \u003c/div\u003e\n  );\n};\n\nexport default ShareButtons;\n```\n\nwith solid domain knowledge and good prompt engineering principles, a human can use Generative AI to truncate the time required to implement such a feature\n\nThis is a simple example to communicate the essential idea outlined above. The actual task is not complicated, but **that’s the point**.\n\nA lot of the work that leads to valuable business outcomes is not complicated, and Generative AI can be used to expedite the implementation of these changes\n\nThe bottom line is that **generative AI makes it fast and easier to implement ideas**","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/20230703011428-Transformers":{"title":"Transformers","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] [Assembly AI](https://www.youtube.com/@AssemblyAI)'s [Transformers for Beginners](https://www.youtube.com/watch?v=_UVfwBqcnbM)\n--\u003e\n\n# Transformers\n\n![[notes/images/Screenshot 2023-07-03 at 1.28.32 AM.png|250]]\n\n- Transformers use [[notes/20230703013343 Attention|Attention]] mechanisms instead of  [[notes/20230703012211 Recurrent Neural Networks (RNNs)|Recurrent Neural Networks (RNNs)]] to remember information, making them faster and parallelizable.\n- The architecture of a transformer includes six \u003cmark style=\"background: #FF5582A6;\"\u003eencoders\u003c/mark\u003e and six \u003cmark style=\"background: #FF5582A6;\"\u003edecoders\u003c/mark\u003e, \n- each encoder has a multi-head self-attention and feed-forward neural network\n- each decoder has 1 multi-head self-attention, 1 masked multi-head attention and 1 feed-forward neural network\n- Inputs are [[notes/20230703031649 Word Embedding|Embedded]] and given [[notes/20230703031923 Positional Encoding|Positional Encoding]]s\n- parallelization is performed with feeding all words of the sentence through the multi-head self-attention layer\n- The words are then passed through the feed-forward neural network. **In each of the 6 encoders, neural networks are different**\n- In between each sub-layer, there are Add and Normalized layer to [[notes/20230703034916 Normalization|Normalize]] the output out of the sub-layer\n- The normalization technique used here is called **Layer Normalization**\n- The output is transformed into a probability distribution over the vocabulary using a linear layer and \u003cmark style=\"background: #FF5582A6;\"\u003esoftmax\u003c/mark\u003e","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["TODO"]},"/notes/20230703012211-Recurrent-Neural-Networks-RNNs":{"title":"Recurrent Neural Networks (RNNs)","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Recurrent Neural Networks (RNNs)\n\n- when provided a sentence RNNs cannot remember the start of a sentence\n- RNNs use recurrence as result cannot be parallelized","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["TODO"]},"/notes/20230703012514-LSTMs":{"title":"LSTMs","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# LSTMs\n\n- LSTMs unlike [[notes/20230703012211 Recurrent Neural Networks (RNNs)|RNNs]] can remember for some time\n- But LSTMs take too long to train","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["TODO"]},"/notes/20230703013343-Attention":{"title":"Attention","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[notes/20230703011428 Transformers|Transformer]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Attention\n\nAttention allows the model to focus on important parts of the input, such as words in a sentence or features in an image\n\n","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["TODO"]},"/notes/20230703031649-Word-Embedding":{"title":"Word Embedding","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Word Embedding\n\nWord Embeddings are **vector representations of words** that **capture semantic and syntactic relationships between words**\n  \nconsider the following words and respective word embeddings in a 3-dimensional space:\n  \n- \"cat\": `[0.2, 0.4, 0.1]`\n- \"dog\": `[0.6, -0.3, 0.5]`\n- \"car\": `[0.8, 0.2, -0.6]`\n- \"bike\": `[0.7, -0.1, -0.4]`\n\nIn this example, each word is represented by a vector of 3 values, which can be interpreted as the word's features or characteristics. \n\nThe values in the embeddings are learned through training algorithms such as Word2Vec or GloVe, which aim to capture the meaning and context of words based on their co-occurrence patterns in a large corpus of text\n\nword embeddings allow the model to capture relationships between words. For instance, in this example, \"cat\" and \"dog\" have similar embeddings with positive values in the first dimension, indicating that these 2 words share some semantic similarity. \n\non the other hand, \"car\" and \"bike\" have negative values in the third dimension, suggesting a potential contrast in their meanings.\n\n\u003cmark style=\"background: #BBFABBA6;\"\u003eword embeddings allow models to represent words as continuous vectors\u003c/mark\u003e and l\u003cmark style=\"background: #BBFABBA6;\"\u003eeverage the geometric properties of these vectors\u003c/mark\u003e to perform tasks like \u003cmark style=\"background: #FF5582A6;\"\u003esemantic similarity\u003c/mark\u003e, \u003cmark style=\"background: #FF5582A6;\"\u003eword analogy\u003c/mark\u003e, or \u003cmark style=\"background: #FF5582A6;\"\u003etext classification\u003c/mark\u003e","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["rn"]},"/notes/20230703031923-Positional-Encoding":{"title":"Positional Encoding","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Positional Encoding\n\nPositional Encoding is used to provide information about the position of words within a sentence. \n\nConsider the sentence: \"The cat sat on the mat.\"\n\nwe first assign a unique position value to each word based on its position in the sentence\n\nwe assume each word is represented by a vector of length N (N=4)\n\nThe positional encoding can be represented as follows\n\n- \"The\" at position 1: `[0.8415, 0.5403, 0.0000, 0.0000]`\n- \"cat\" at position 2: `[0.9093, -0.4161, 0.0000, 0.0000]`\n- \"sat\" at position 3: `[-0.7568, -0.6536, 0.0000, 0.0000]`\n- \"on\" at position 4: `[-0.9589, 0.2837, 0.0000, 0.0000]`\n- \"the\" at position 5: `[0.1411, -0.9900, 0.0000, 0.0000]`\n- \"mat\" at position 6: `[-0.2794, 0.9602, 0.0000, 0.0000]`\n\nIn this example, each positional encoding vector contains four elements, representing different dimensions or features. \n\nThe values are determined using mathematical functions such as sine and cosine functions, to create distinct encoding patterns for each position\n\nThese positional encodings are then combined with word embeddings to provide the transformer model with both word-specific and position-specific information\n\nIt enables the transformer to understand the sequential structure of the input sentence.\n","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["rn"]},"/notes/20230703034916-Normalization":{"title":"Normalization","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Normalization\n\nNormalization, in the context of machine learning, refers to the process of standardizing or scaling data to a common range or distribution. \n\nIt is often applied to features or variables in a dataset to ensure that the data have similar scales or magnitudes\n\nNormalization helps to avoid biases or undue influences that might arise from features with different scales. \n\nThe algorithm can compare and weigh the contributions of different features without a particular feature dominating the learning process based on its scale.\n\nThere are various methods of normalization, but most commonly used techniques are\n\n1.  Min-Max Scaling (Normalization): This method scales the values of a feature to a fixed range, typically between 0 and 1. It is achieved by subtracting the minimum value of the feature and dividing it by the difference between the maximum and minimum values. The formula for min-max scaling is: normalized\\_value = (value - min\\_value) / (max\\_value - min\\_value)\n    \n2.  Z-Score Standardization: This method transforms the values of a feature to have a mean of 0 and a standard deviation of 1. It is achieved by subtracting the mean of the feature and dividing it by the standard deviation. The formula for z-score standardization is: standardized\\_value = (value - mean) / standard\\_deviation\n\n**Normalization should be applied to numerical features, not categorical features**\n\nIt is important to note that **normalization is not always necessary or beneficial** for every machine learning algorithm. \n\nsome algorithms like **Decision Trees or Random Forests, are not affected by feature scales** unlike others, like Logistic Regression or Neural Networks\n","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["rn"]},"/notes/20230703043154-Vector-Database":{"title":"Vector Database","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] [A Gentle Introduction to Vector Databases](https://frankzliu.com/blog/a-gentle-introduction-to-vector-databases)\n- [ ] [Vector Databases Demystified: Part 1 - An Introduction to the World of High-Dimensional Data Storage](https://www.linkedin.com/pulse/vector-databases-demystified-part-1-introduction-world-adie-kaye)\n- [ ] [Vector Databases Demystified: Part 2 - Building Your Own (Very) Simple Vector Database in Python](https://www.linkedin.com/pulse/vector-databases-demystified-part-2-building-your-own-adie-kaye)\n- [ ] [Vector Databases Demystified: Part 3 - Build a colour matching app with Pinecone](https://www.linkedin.com/pulse/vector-databases-demystified-part-3-build-colour-matching-adie-kaye?trk=public_profile_article_view)\n- [ ] [Vector Databases Demystified: Part 4 - Using Sentence Transformers with Pinecone](https://www.linkedin.com/pulse/vector-databases-demystified-part-4-using-sentence-pinecone-kaye?trk=public_profile_article_view)\n- [ ] [Fine Tuning Your Own Sentence Transformers with Python](https://www.linkedin.com/pulse/fine-tuning-your-own-sentence-transformers-python-adie-kaye?trk=public_profile_article_view)\n- [ ] [What are your thoughts/experiences with building vector databases for AI/MLOps?](https://www.reddit.com/r/dataengineering/comments/m3hndj/what_are_your_thoughtsexperiences_with_building/)\n- [ ] [Benchmarking Nearest Neighbors](https://github.com/erikbern/ann-benchmarks)\n--\u003e\n\n# Vector Database\n\nThese databases contain arrays of numbers clustered together based on similarities, which can be queried with ultra-low latencies\n\nIn other words, vector databases index vectors for fast search and retrieval by comparing values and finding those that are most similar to one another.\n\nvector databases can used to store [[notes/20230703031649 Word Embedding|Embedding]]s and perform queries\n\nwe can use vector databases to \u003cmark style=\"background: #BBFABBA6;\"\u003eextend large language models with long-term memory\u003c/mark\u003e\n\n- start with general-purpose model, like GPT-4, [LLaMA](https://github.com/facebookresearch/llama), or [LaMDA](https://blog.google/technology/ai/lamda/) but provide custom data in a vector database. \n- When a user gives a prompt, we can run queries for relevant documents in the database to update the context, which will customize the final response. \n\nvector databases integrate with tools like [[notes/20230703061520 LangChain|LangChain]] that combine multiple LLMs together\n\n## List of Vector Databases\n\n- closed-source\n  - [pinecone](https://www.pinecone.io)\n- open-source\n  - [[notes/20230703070807 PgVector|PgVector]]\n    - vector storage\n    - indexing\n    - recall\n  - [chroma](https://github.com/chroma-core/chroma)\n  - [weaviate](https://github.com/weaviate/weaviate)\n  - [milvus](https://github.com/milvus-io/milvus)\n  - [qrant](https://github.com/qdrant/qdrant)\n  - [faiss](https://github.com/facebookresearch/faiss)\n  - [llama_index](https://github.com/jerryjliu/llama_index)\n","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["TODO"]},"/notes/20230703060600-Build-Your-Own":{"title":"Build Your Own","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] []()\n--\u003e\n\n# Build Your Own\n\n- [ ] [[notes/20230628031147 Generative Pretrained Transformer (GPT)|GPT]]\n  - [ ] [nanoGPT](https://github.com/karpathy/nanoGPT) \n  - [ ] [miniGPT](https://github.com/karpathy/minGPT)\n- [ ] [[notes/20230703043154 Vector Database|Vector Database]]\n  - [ ] [Vector Databases Demystified: Part 2 - Building Your Own (Very) Simple Vector Database in Python](https://www.linkedin.com/pulse/vector-databases-demystified-part-2-building-your-own-adie-kaye)","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/20230703061520-LangChain":{"title":"LangChain","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] []()\n--\u003e\n\n#  LangChain\n\n[LangChain](https://github.com/hwchase17/langchain) is a framework for developing applications powered by language models\n\n- It can call a language model via an API\n- It can also connect [[notes/20230628030810 Large Language Models (LLMs)|LLMs]], like GPT-4, LLaMDA, and LLaMA, to other sources of data such as Google Drive, Wikipedia and allow them to interact with them \n- It can chain commands together so the AI model can know what it needs to do to produce the results or perform the actions needed\n\n## Features\n\n![[notes/20230703063700 Agents|Agents]]\n\n![[notes/20230703063746 Memory|Memory]]","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/20230703063700-Agents":{"title":"Agents","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[notes/20230703061520 LangChain|LangChain]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] []()\n--\u003e\n\n# Agents\n\nAgents are a method of using a language model as a reasoning engine to determine how to interact with the outside world based on the user's input.\n\nAgents have access to a suite of tools and, depending on the input, an agent can decide which tools to call.","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/20230703063746-Memory":{"title":"Memory","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[notes/20230703061520 LangChain|LangChain]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] []()\n--\u003e\n\n# Memory\n\nLLMs process each query independently of other interactions. \n\nLangChain provides memory components to manage and manipulate previous chat messages and incorporate them into chains. \n\nLangChain's memory components can be used to retrieve data from memory or store data in memory. \n\nThis is important for chatbots, for example, which need to remember previous conversations.","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/20230703063839-Alternatives-to-LangChain":{"title":"Alternatives to LangChain","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] []()\n--\u003e\n\n# Alternatives to LangChain\n\n- [AutoGPT](https://autogpt.net)\n  - Auto-GPT has tendencies where it gets stuck in infinite logic loops and rabbit holes\n- [AgentGPT](https://agentgpt.reworkd.ai/)\n- [BabyAGI](https://github.com/yoheinakajima/babyagi)\n- [LangDock](https://www.langdock.com)\n- [GradientJ](https://gradientj.com)\n- [FlowiseAI](https://flowiseai.com)\n- [TensorFlow](https://www.tensorflow.org/)","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/20230703070807-PgVector":{"title":"PgVector","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] []()\n--\u003e\n\n# PgVector\n\n- [PgVector](https://github.com/pgvector/pgvector) supports up to 16,000 dimensions for storage and 2,000 for indexing\n- PgVector supports exact KNN which is what most apps just starting their journey (\u003c10k docs) need\n- It supports IVF ANN for larger collections\n- postgres natively supports several additional composite index types, including BTREE GIST and GIN, for tabular, text and json data in addition to vector indexes.\n- SQL databases in general (along w/ OpenSearch) are significantly (orders of magnitude) ahead of Pinecone in terms of scalability which limits a pod size to ~5M vectors\n- The HNSW algorithmic advantage may be 2-10x as fast as IVF __in memory__, but it's \u003cmark style=\"background: #BBFABBA6;\"\u003e100x slower to go over the network to a different datacenter like Pinecone \u003c/mark\u003ethan using the database in the same VPC, so that \"advantage\" is situational at best\n- [[notes/20230703073417 PostgresML|PostgresML]] takes another network trip out of the equation\n- Beside the simple vector recall, It runs the embedding model itself on input text inside the same memory space","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/20230703073417-PostgresML":{"title":"PostgresML","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] [Generating LLM embeddings with open source models in PostgresML](https://postgresml.org/blog/generating-llm-embeddings-with-open-source-models-in-postgresml)\n--\u003e\n\n# [PostgresML](https://github.com/postgresml/postgresml)\n","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["TODO"]},"/notes/20230703150959-Usecases":{"title":"Usecases","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] []()\n--\u003e\n\n# Usecases\n\n- [[notes/20230711082511 Campaign Creation to Tactic Authoring|Campaign Creation to Tactic Authoring]]\n- [[notes/20230711101408 Content Repurposing (Email to Video)|Content Repurposing (Email to Video)]]\n- DAMS Semantic Search Enablement\n- Semantic Question \u0026 Answer\n- generative AI for concept arts\n  - tinder like interface for human review/feedback\n  - track line of sight to build heatmaps of attention (reminds me of the paper spandan worked on)","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/20230711082511-Campaign-Creation-to-Tactic-Authoring":{"title":"Campaign Creation to Tactic Authoring","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] []()\n--\u003e\n\n# Campaign Creation to Tactic Authoring\n\n![[notes/images/Screenshot 2023-07-11 at 8.27.57 AM.png]]\n\n## Inputs\n\n- Custom Built Compliant Prompt\n\n## Planes\n\n- campaign strategy creation\n  - ChatGPT\n- content copy creation\n  - ChatGPT\n- Realistic \u0026 Brand Compliant Image Creation\n  - MidJourney\n\n## Output\n\n- HTML Code Generation\n- Responsive\n- Brand Compilant","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/20230711101408-Content-Repurposing-Email-to-Video":{"title":"Content Repurposing (Email to Video)","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] []()\n--\u003e\n\n# Content Repurposing (Email to Video)\n\n![[notes/images/Screenshot 2023-07-11 at 1.46.22 PM.png]]\n\n- provide prompt as text\n- ask ChatGPT to write me a script/scene\n- use [[notes/20230711171651 MidJourneyAI|MidJourneyAI]] to create images\n- use [[notes/20230711172239 Eleven Labs|Eleven Labs]] speech synthesis to generate audio\n- animate each character using [[notes/20230711172730 D-ID AI|D-ID AI]]\n- ffmpeg or video editor (like ) to join clip together","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/20230711171651-MidJourneyAI":{"title":"MidJourneyAI","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] []()\n--\u003e\n\n# MidJourney AI\n\nannual subscription cost for basic plan cost $96\n\n## Tips\n\n- how to change the aspect ratio of images\n  - include “—ar 3:2” in the prompt\n  - include “full body” if you don’t want super close-ups\n- add term “cinematic,” to prompts\n- add specific dates for reference.\n\n## Prompts\n\n\u003e “Frodo Baggins, portrait, full body, cinematic, film still, in the style of a Wes Anderson live-action movie circa 2008 —ar 3:2.”\n\n\u003e Owen Wilson as Legolas the elf, portrait, full body, cinematic, holding a bow and arrow, symmetrical, facing forward, film still, exterior shot, daytime, in the style of a Wes Anderson live-action movie circa 2008 —ar 3:2.”\n","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/20230711172239-Eleven-Labs":{"title":"Eleven Labs","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] []()\n--\u003e\n\n# [Elevenlabs](https://beta.elevenlabs.io/) \n\n$5 per month\n\n- requires clips where there was zero background noise and voice is clear\n- how did automatic detect background noise","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/20230711172730-D-ID-AI":{"title":"D-ID AI","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- [ ] []()\n--\u003e\n\n# D-ID AI \n\n$4.99 per month\n\nwhere you can either type out a script for each character to say or upload an existing sound bite. \n\nI did the latter for Frodo and Gandalf, and for the other characters who didn’t have speaking roles but still needed to look, y’know, alive, I inserted a series of “pauses” into their speech box. \n\ncharacters blink and move heads around a bit","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":[""]},"/notes/4Tasks":{"title":"The 4 Tasks","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Campaign Creation to Tatic Authoring: \n- OpenAI API/Langchain\n\n# Content Repurposing (Email to Video): \n- Langchain/OpenAI (Create text)\n- Happyaccidents/playgrounds (Text to image)\n- TBD (Ai Video generator)\n\n# Semantic Search: \n- Supabase (OpenAI CLIP Model and Supabase Vector)\n\n# Semantic QnA: \n- Langchain","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["In Progress"]},"/notes/Generative_AI":{"title":"Generative AI","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n- [[notes/20230628030800 Checklist.md | Checklist]]\n- [[notes/20230628030801 Links.md | Links]]\n- [[notes/Shared_Links.md | Shared Links]]\n- [[notes/4Tasks.md | THE 4 Tasks]]\n- [[notes/20230628030810 Large Language Models (LLMs).md | Large Language Models (LLMs)]]\n- [[notes/20230628030901 Generative AI.md | Generative AI]]\n- [[notes/20230628030911 Build GPT from scratch.md | Build GPT from scratch]]\n- [[notes/20230628031147 Generative Pretrained Transformer (GPT).md | Generative Pretrained Transformer (GPT)]]\n- [[notes/20230628031546 Generative Adversarial Networks (GANs).md | Generative Adversarial Networks (GANs)]]\n- [[notes/20230628032202 How does GPT work.md | How does GPT work]]\n- [[notes/20230628033256 GPT-3.md | GPT-3]]\n- [[notes/20230630020251 Discriminative AI.md | Discriminative AI]]\n- [[notes/20230630020526 Generative AI vs Discriminative AI - A mathematical perspective.md | Generative AI vs Discriminative AI - A mathematical perspective]]\n- [[notes/20230630020526 Generative AI vs Discriminative AI.md | Generative AI vs Discriminative AI]]\n- [[notes/20230630021015 Conditional Distribution.md | Conditional Distribution]]\n- [[notes/20230630021029 Joint Distribution.md | Joint Distribution]]\n- [[notes/20230630041814 Generative AI - A Mathematical Perspective.md | Generative AI - A Mathematical Perspective]]\n- [[notes/20230630042526 ChatGPT.md | ChatGPT]]\n- [[notes/20230630042902 How to use Generative AI.md | How to use Generative AI]]\n- [[notes/20230702204625 Modern Generative AI.md | Modern Generative AI]]\n- [[notes/20230702210325 Add a button to product page to share the product.md | Add a button to product page to share the product]]\n- [[notes/20230703011428 Transformers.md | Transformers]]\n- [[notes/20230703012211 Recurrent Neural Networks (RNNs).md | Recurrent Neural Networks (RNNs)]]\n- [[notes/20230703012514 LSTMs.md | LSTMs]]\n- [[notes/20230703013343 Attention.md | Attention]]\n- [[notes/20230703031649 Word Embedding.md | Word Embedding]]\n- [[notes/20230703031923 Positional Encoding.md | Positional Encoding]]\n- [[notes/20230703034916 Normalization.md | Normalization]]\n- [[notes/20230703043154 Vector Database.md | Vector Database]]\n- [[notes/20230703060600 Build Your Own.md | Build Your Own]]\n- [[notes/20230703061520 LangChain.md | LangChain]]\n- [[notes/20230703063700 Agents.md | Agents]]\n- [[notes/20230703063746 Memory.md | Memory]]\n- [[notes/20230703063839 Alternatives to LangChain.md | Alternatives to LangChain]]\n- [[notes/20230703070807 PgVector.md | PgVector]]\n- [[notes/20230703073417 PostgresML.md | PostgresML]]\n- [[notes/20230703150959 Usecases.md | Usecases]]\n- [[notes/20230711082511 Campaign Creation to Tactic Authoring.md | Campaign Creation to Tactic Authoring]]\n- [[notes/20230711101408 Content Repurposing (Email to Video).md | Content Repurposing (Email to Video)]]\n- [[notes/20230711171651 MidJourneyAI.md | MidJourneyAI]]\n- [[notes/20230711172239 Eleven Labs.md | Eleven Labs]]\n- [[notes/20230711172730 D-ID AI.md | D-ID AI]]","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["In Progress"]},"/notes/Shared_Links":{"title":"Shared Links","content":"\n\u003c!-- \ntags: \n--\u003e\n\n\u003c!--internal\nparent:: [[]]\nchild:: [[]]\nrelated:: [[]]\n--\u003e\n\n\u003c!--external\n- []()\n--\u003e\n\n# Links\n\n- [https://github.com/gradio-app/gradio](https://github.com/gradio-app/gradio)\n- [https://huggingface.co/spaces](https://huggingface.co/spaces)\n- [https://huggingface.co/spaces/THUDM/CogVideo](https://huggingface.co/spaces/THUDM/CogVideo)\n- [https://filmora.wondershare.com/ai/alternative-to-synthesia-for-ai-video-generation.html?gclid=Cj0KCQjwk96lBhDHARIsAEKO4xYtIMxfYk4zp4nCTpB5sCBmuShbdSGzN5Q0HTsEfEUQxsjgbbIFFbgaAjD1EALw_wcB](https://filmora.wondershare.com/ai/alternative-to-synthesia-for-ai-video-generation.html?gclid=Cj0KCQjwk96lBhDHARIsAEKO4xYtIMxfYk4zp4nCTpB5sCBmuShbdSGzN5Q0HTsEfEUQxsjgbbIFFbgaAjD1EALw_wcB)\n- [https://playgroundai.com/create?](https://playgroundai.com/create?)\n- [https://poe.com/ChatGPT](https://poe.com/ChatGPT)\n- [https://www.perplexity.ai/](https://www.perplexity.ai/)\n- [https://chat.forefront.ai/](https://chat.forefront.ai/)\n- [https://docs.synthesia.io/reference/auth](https://docs.synthesia.io/reference/auth)\n- [https://elevenlabs.io/pricing](https://elevenlabs.io/pricing)\n- [https://github.com/AUTOMATIC1111/stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui)\n- [https://www.reddit.com/r/StableDiffusion/comments/134yxoc/any_free_alternatives_to_midjourney/](https://www.reddit.com/r/StableDiffusion/comments/134yxoc/any_free_alternatives_to_midjourney/)\n- [https://github.com/DevkraftTechnologies/langchain](https://github.com/DevkraftTechnologies/langchain)\n- [https://www.eraser.io/home](https://www.eraser.io/home)\n- [https://www.happyaccidents.ai/](https://www.happyaccidents.ai/)\n- [https://robocorp.com/portal/robot/ekipalen/Assistant-OpenAI-test](https://robocorp.com/portal/robot/ekipalen/Assistant-OpenAI-test)\n- [https://supabase.com/docs/guides/ai/examples/image-search-openai-clip](https://supabase.com/docs/guides/ai/examples/image-search-openai-clip)\n- [https://supabase.com/docs/guides/cli](https://supabase.com/docs/guides/cli)","lastmodified":"2023-07-24T06:16:07.106957245Z","tags":["In Progress"]}}